import express from 'express';
import bodyParser from 'body-parser';
import fs from 'fs';
import { v4 as uuidv4 } from 'uuid';
import PptxGenJS from 'pptxgenjs';
import registerAgentEndpoints from './agentEndpoints';

const app = express();

// CORS ‰∏≠Èñì‰ª∂
app.use((req, res, next) => {
  const allowedOrigins = ['http://localhost:5173', 'http://localhost:3001', 'http://localhost:3000'];
  const origin = req.headers.origin;
  
  if (allowedOrigins.includes(origin)) {
    res.setHeader('Access-Control-Allow-Origin', origin);
  }
  
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');
  res.setHeader('Access-Control-Allow-Credentials', 'true');
  
  if (req.method === 'OPTIONS') {
    return res.sendStatus(204);
  }
  
  next();
});

app.use(bodyParser.json({ limit: '10mb' }));

// ÂÅ•Â∫∑Ê™¢Êü•Á´ØÈªû
app.get('/health', (req, res) => {
  res.json({ status: 'ok', port: process.env.PORT || 3001 });
});

// ÁîüÊàê NotebookLM Ê†ºÂºèÁöÑ Markdown Â†±Âëä
function generateNotebookLMReport(prompt, results) {
  const timestamp = new Date().toISOString();
  const summary = Object.entries(results)
    .map(([k, v]) => `- **${k.toUpperCase()}**: ${(v?.toString() || 'N/A').substring(0, 100)}...`)
    .join('\n');

  return `# AI Aggregation Report

**Generated**: ${timestamp}
**Analysis Prompt**: ${prompt}

## Executive Summary

This report aggregates responses from multiple AI models analyzing the given prompt.

## AI Model Responses

${Object.entries(results)
  .map(
    ([k, v]) => `
### ${k.toUpperCase()}

\`\`\`
${v}
\`\`\`
`
  )
  .join('\n')}

## Analysis Insights

### Key Findings
${summary}

### Comparative Analysis

The following AI models were consulted:
${Object.keys(results).map((k) => `- ${k.toUpperCase()}`).join('\n')}

This aggregated analysis provides a comprehensive perspective from multiple AI sources.

---
*Report generated by Telecom Prompt Aggregation System*
`;
}

// ÁîüÊàê HTML Â†±Âëä
function generateHTMLReport(prompt, results) {
  const timestamp = new Date().toISOString();
  const resultsHTML = Object.entries(results)
    .map(
      ([k, v]) => `
    <section class="model-section">
      <h3>${k.toUpperCase()}</h3>
      <div class="model-content"><pre>${escapeHtml(v.toString())}</pre></div>
    </section>
    `
    )
    .join('\n');

  return `<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Aggregation Report</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      padding: 2rem;
    }
    .container {
      max-width: 1200px;
      margin: 0 auto;
      background: white;
      border-radius: 12px;
      box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
      overflow: hidden;
    }
    .header {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 3rem 2rem;
      text-align: center;
    }
    .header h1 {
      font-size: 2.5rem;
      margin-bottom: 1rem;
    }
    .header p {
      font-size: 1rem;
      opacity: 0.9;
    }
    .content {
      padding: 2rem;
    }
    .prompt-section {
      background: #f8f9fa;
      padding: 1.5rem;
      border-radius: 8px;
      margin-bottom: 2rem;
      border-left: 4px solid #667eea;
    }
    .prompt-section h2 {
      color: #333;
      margin-bottom: 0.5rem;
      font-size: 1.1rem;
    }
    .prompt-section p {
      color: #666;
      line-height: 1.6;
    }
    .model-section {
      margin-bottom: 2rem;
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      overflow: hidden;
    }
    .model-section h3 {
      background: #f5f5f5;
      color: #333;
      padding: 1rem;
      border-bottom: 2px solid #667eea;
      font-size: 1.2rem;
    }
    .model-content {
      padding: 1.5rem;
      background: white;
    }
    .model-content pre {
      background: #f8f9fa;
      padding: 1rem;
      border-radius: 4px;
      overflow-x: auto;
      line-height: 1.5;
      color: #333;
      max-height: 400px;
      overflow-y: auto;
    }
    .footer {
      background: #f8f9fa;
      padding: 1rem;
      text-align: center;
      color: #666;
      font-size: 0.9rem;
      border-top: 1px solid #e0e0e0;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ü§ñ AI Aggregation Report</h1>
      <p>Comprehensive Analysis from Multiple AI Models</p>
    </div>
    <div class="content">
      <div class="prompt-section">
        <h2>üìù Analysis Prompt</h2>
        <p>${escapeHtml(prompt)}</p>
      </div>
      <div class="timestamp" style="text-align: right; color: #999; font-size: 0.9rem; margin-bottom: 2rem;">
        Generated: ${timestamp}
      </div>
      ${resultsHTML}
    </div>
    <div class="footer">
      <p>This report was generated by Telecom Prompt Aggregation System v1.1</p>
      <p>Aggregating responses from: ${Object.keys(results).map((k) => k.toUpperCase()).join(', ')}</p>
    </div>
  </div>
</body>
</html>`;
}

function escapeHtml(text) {
  const map = {
    '&': '&amp;',
    '<': '&lt;',
    '>': '&gt;',
    '"': '&quot;',
    "'": '&#039;',
  };
  return text.replace(/[&<>"']/g, (m) => map[m]);
}

// ËÅöÂêàÂ§öÂÄã AI Ê®°ÂûãÂõûÊáâ‰∏¶ÁîüÊàê PPT
app.post('/api/aggregate', async (req, res) => {
  console.log('üì® Received aggregation request');
  const { prompt } = req.body;
  
  if (!prompt) {
    console.error('‚ùå No prompt provided');
    return res.status(400).json({ error: 'prompt required' });
  }

  console.log('üîç Prompt received:', prompt.slice(0, 50) + '...');

  try {
    const results = {};

    // OpenAI (ChatGPT)
    if (process.env.OPENAI_API_KEY) {
      console.log('üìû Calling OpenAI API...');
      try {
        const r = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          },
          body: JSON.stringify({ model: 'gpt-4o-mini', messages: [{ role: 'user', content: prompt }], max_tokens: 800 }),
        });
        const j = await r.json();
        results.chatgpt = j.choices?.[0]?.message?.content || JSON.stringify(j, null, 2);
        console.log('‚úÖ OpenAI success');
      } catch (e) {
        console.error('‚ùå OpenAI error:', e.message);
        results.chatgpt = `Error: ${e.message}`;
      }
    } else {
      console.log('‚è≠Ô∏è  Skipping OpenAI (no API key)');
    }

    // Google Gemini
    if (process.env.GEMINI_API_KEY) {
      console.log('üìû Calling Gemini API...');
      try {
        const r = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${process.env.GEMINI_API_KEY}`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] }),
        });
        const j = await r.json();
        results.gemini = j.candidates?.[0]?.content?.parts?.[0]?.text || JSON.stringify(j, null, 2);
        console.log('‚úÖ Gemini success');
      } catch (e) {
        console.error('‚ùå Gemini error:', e.message);
        results.gemini = `Error: ${e.message}`;
      }
    } else {
      console.log('‚è≠Ô∏è  Skipping Gemini (no API key)');
    }

    // Claude (Anthropic)
    if (process.env.CLAUDE_API_KEY) {
      console.log('üìû Calling Claude API...');
      try {
        const r = await fetch('https://api.anthropic.com/v1/messages', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-api-key': process.env.CLAUDE_API_KEY,
            'anthropic-version': '2023-06-01',
          },
          body: JSON.stringify({ model: 'claude-3-haiku-20240307', max_tokens: 1024, messages: [{ role: 'user', content: prompt }] }),
        });
        const j = await r.json();
        results.claude = j.content?.[0]?.text || JSON.stringify(j, null, 2);
        console.log('‚úÖ Claude success');
      } catch (e) {
        console.error('‚ùå Claude error:', e.message);
        results.claude = `Error: ${e.message}`;
      }
    } else {
      console.log('‚è≠Ô∏è  Skipping Claude (no API key)');
    }

    // Perplexity
    if (process.env.PERPLEXITY_API_KEY) {
      console.log('üìû Calling Perplexity API...');
      try {
        const r = await fetch('https://api.perplexity.ai/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ model: 'pplx-70b-online', messages: [{ role: 'user', content: prompt }], max_tokens: 800 }),
        });
        const j = await r.json();
        results.perplexity = j.choices?.[0]?.message?.content || JSON.stringify(j, null, 2);
        console.log('‚úÖ Perplexity success');
      } catch (e) {
        console.error('‚ùå Perplexity error:', e.message);
        results.perplexity = `Error: ${e.message}`;
      }
    } else {
      console.log('‚è≠Ô∏è  Skipping Perplexity (no API key)');
    }

    // Copilot (Azure OpenAI)
    if (process.env.AZURE_OPENAI_KEY && process.env.AZURE_OPENAI_ENDPOINT) {
      console.log('üìû Calling Copilot (Azure OpenAI) API...');
      try {
        const endpoint = process.env.AZURE_OPENAI_ENDPOINT;
        const deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT || 'gpt-4';
        const r = await fetch(`${endpoint}/openai/deployments/${deploymentName}/chat/completions?api-version=2024-02-15-preview`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'api-key': process.env.AZURE_OPENAI_KEY,
          },
          body: JSON.stringify({ messages: [{ role: 'user', content: prompt }], max_tokens: 800 }),
        });
        const j = await r.json();
        results.copilot = j.choices?.[0]?.message?.content || JSON.stringify(j, null, 2);
        console.log('‚úÖ Copilot success');
      } catch (e) {
        console.error('‚ùå Copilot error:', e.message);
        results.copilot = `Error: ${e.message}`;
      }
    } else {
      console.log('‚è≠Ô∏è  Skipping Copilot (no Azure OpenAI credentials)');
    }

    // Â¶ÇÊûúÊ≤íÊúâ‰ªª‰ΩïÁµêÊûúÔºåËøîÂõûÈåØË™§
    if (Object.keys(results).length === 0) {
      console.error('‚ùå No results - no API keys configured');
      return res.status(400).json({ error: 'No API keys configured. Please set at least one of: OPENAI_API_KEY, GEMINI_API_KEY, CLAUDE_API_KEY, PERPLEXITY_API_KEY' });
    }

    console.log('üìä Results collected:', Object.keys(results).join(', '));
    console.log('üé® Generating PPTX...');

    // ÁîüÊàê PPT
    const pres = new PptxGenJS();
    pres.title = 'AI Aggregation Results';
    pres.subject = prompt;
    pres.creator = 'Telecom Prompt Generator';

    // Ê®ôÈ°åÈ†Å
    const titleSlide = pres.addSlide();
    titleSlide.background = { color: '1F2937' };
    titleSlide.addText('AI Aggregation Results', { x: 0.5, y: 2.5, w: 9, h: 1.5, fontSize: 48, bold: true, color: 'FFFFFF', align: 'center' });
    titleSlide.addText(`Prompt: ${prompt.slice(0, 100)}...`, { x: 0.5, y: 4.2, w: 9, h: 1, fontSize: 18, color: 'D1D5DB', align: 'center', fontFace: 'Arial' });

    // ÂÖßÂÆπÈ†Å
    Object.entries(results).forEach(([k, v]) => {
      const slide = pres.addSlide();
      slide.background = { color: 'FFFFFF' };
      slide.addText(k.toUpperCase(), { x: 0.5, y: 0.5, w: 9, fontSize: 32, bold: true, color: '1F2937' });
      
      const content = typeof v === 'string' ? v : JSON.stringify(v, null, 2);
      const truncated = content.length > 3500 ? content.slice(0, 3500) + '\n...' : content;
      
      slide.addText(truncated, {
        x: 0.5, y: 1.2, w: 9, h: 5.3, fontSize: 11, color: '374151', wrap: true, fontFace: 'Courier New',
      });
    });

    // ÁîüÊàê PPTX ÁÇ∫ Base64
    console.log('üíæ Writing PPTX to buffer...');
    const buffer = await pres.write({ outputType: 'arraybuffer' });
    const base64 = Buffer.from(buffer).toString('base64');

    console.log('üì¶ PPTX generated successfully, sending response...');
    res.json({ ok: true, pptx: base64, fileName: `ai-aggregation-${new Date().getTime()}.pptx` });
    console.log('‚úÖ Response sent successfully');

  } catch (err) {
    console.error('‚ùå Aggregate error:', err);
    console.error('Error stack:', err.stack);
    res.status(500).json({ error: err.message || 'internal error', stack: err.stack });
  }
});

// Êñ∞Á´ØÈªûÔºöÁîüÊàê NotebookLM Ê†ºÂºèÁöÑ Markdown Â†±Âëä
app.post('/api/report/markdown', async (req, res) => {
  console.log('üìã Generating Markdown report');
  const { prompt, results } = req.body;

  if (!prompt || !results) {
    return res.status(400).json({ error: 'prompt and results required' });
  }

  try {
    const markdown = generateNotebookLMReport(prompt, results);
    const fileName = `ai-report-${new Date().getTime()}.md`;
    
    res.json({
      ok: true,
      markdown: markdown,
      fileName: fileName,
      content: Buffer.from(markdown).toString('base64'),
    });
    console.log('‚úÖ Markdown report generated');
  } catch (err) {
    console.error('‚ùå Markdown report error:', err);
    res.status(500).json({ error: err.message });
  }
});

// Êñ∞Á´ØÈªûÔºöÁîüÊàê HTML Â†±Âëä
app.post('/api/report/html', async (req, res) => {
  console.log('üìä Generating HTML report');
  const { prompt, results } = req.body;

  if (!prompt || !results) {
    return res.status(400).json({ error: 'prompt and results required' });
  }

  try {
    const html = generateHTMLReport(prompt, results);
    const fileName = `ai-report-${new Date().getTime()}.html`;
    
    res.json({
      ok: true,
      html: html,
      fileName: fileName,
      content: Buffer.from(html).toString('base64'),
    });
    console.log('‚úÖ HTML report generated');
  } catch (err) {
    console.error('‚ùå HTML report error:', err);
    res.status(500).json({ error: err.message });
  }
});

// Êñ∞Á´ØÈªûÔºöÊü•Ë©¢ÊâÄÊúâÊîØÊåÅÁöÑ AI Ê®°Âûã
app.get('/api/models', (req, res) => {
  const models = {
    available: [],
    unavailable: [],
  };

  const modelChecks = [
    { name: 'ChatGPT (OpenAI)', key: 'OPENAI_API_KEY' },
    { name: 'Gemini (Google)', key: 'GEMINI_API_KEY' },
    { name: 'Claude (Anthropic)', key: 'CLAUDE_API_KEY' },
    { name: 'Perplexity', key: 'PERPLEXITY_API_KEY' },
    { name: 'Copilot (Azure)', key: 'AZURE_OPENAI_KEY' },
  ];

  modelChecks.forEach((model) => {
    if (process.env[model.key]) {
      models.available.push(model.name);
    } else {
      models.unavailable.push(model.name);
    }
  });

  res.json({
    status: 'ok',
    totalAvailable: models.available.length,
    availableModels: models.available,
    unavailableModels: models.unavailable,
  });
  console.log('üì° Available models:', models.available.join(', '));
});

const port = process.env.PORT || 3001;

// Ê≥®ÂÜå Agent Á´ØÁÇπ
registerAgentEndpoints(app);

const server = app.listen(port, () => {
  console.log(`üöÄ Server listening on http://localhost:${port}`);
  console.log('‚ú® Available API Endpoints:');
  console.log(`  POST /api/aggregate - Generate PPT from all AI models`);
  console.log(`  POST /api/report/markdown - Generate NotebookLM-compatible Markdown report`);
  console.log(`  POST /api/report/html - Generate HTML report`);
  console.log(`  GET /api/models - Check available AI models`);
  console.log('ü§ñ Agent API Endpoints:');
  console.log(`  POST /api/agent/call - Call Agent with intelligent routing and caching`);
  console.log(`  POST /api/agent/call-stream - Stream Agent responses (SSE)`);
  console.log(`  GET /api/agent/models - Get available AI models from Agent`);
  console.log(`  GET /api/agent/mcp-info - Get MCP server information`);
  console.log(`  GET /api/agent/mcp-tools - Get MCP tools list`);
  console.log(`  POST /api/agent/mcp-tool-call - Call an MCP tool`);
  console.log(`  GET /api/agent/cache-stats - Get cache statistics`);
  console.log(`  POST /api/agent/clear-cache - Clear the cache`);
  console.log(`  GET /api/agent/history - Get execution history`);
  console.log(`  GET /api/agent/health - Agent health check`);
  console.log('üîë Environment variables:');
  console.log(`  OPENAI_API_KEY: ${process.env.OPENAI_API_KEY ? '‚úÖ set' : '‚ùå not set'}`);
  console.log(`  GEMINI_API_KEY: ${process.env.GEMINI_API_KEY ? '‚úÖ set' : '‚ùå not set'}`);
  console.log(`  CLAUDE_API_KEY: ${process.env.CLAUDE_API_KEY ? '‚úÖ set' : '‚ùå not set'}`);
  console.log(`  PERPLEXITY_API_KEY: ${process.env.PERPLEXITY_API_KEY ? '‚úÖ set' : '‚ùå not set'}`);
  console.log(`  AZURE_OPENAI_KEY: ${process.env.AZURE_OPENAI_KEY ? '‚úÖ set' : '‚ùå not set'}`);
  console.log(`  AZURE_OPENAI_ENDPOINT: ${process.env.AZURE_OPENAI_ENDPOINT ? '‚úÖ set' : '‚ùå not set'}`);
});

// Êú™ËôïÁêÜÁöÑÊãíÁµï
process.on('unhandledRejection', (reason, promise) => {
  console.error('‚ö†Ô∏è Unhandled Rejection at:', promise, 'reason:', reason);
});

// Êú™ÊçïÁç≤ÁöÑÁï∞Â∏∏
process.on('uncaughtException', (err) => {
  console.error('‚ö†Ô∏è Uncaught Exception:', err);
});

